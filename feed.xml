<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://github.com/pages/peerannot/peerannot/feed.xml" rel="self" type="application/atom+xml" /><link href="https://github.com/pages/peerannot/peerannot/" rel="alternate" type="text/html" /><updated>2023-08-09T08:42:37+00:00</updated><id>https://github.com/pages/peerannot/peerannot/feed.xml</id><title type="html">Peerannot</title><subtitle>Handling your crowdsourced datasets</subtitle><entry><title type="html">Entropy</title><link href="https://github.com/pages/peerannot/peerannot/models/entropy/" rel="alternate" type="text/html" title="Entropy" /><published>2023-08-09T00:00:00+00:00</published><updated>2023-08-09T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/entropy</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/entropy/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The entropy identification measures how diverse the labels answered to a given task are.
With enough labels, tasks with high entropy can be identified as potential ambiguities/difficulties.
A task with a null-entropy has reached perfect consensus.</p>

<p>More formally, let task $x_i\in\mathcal{X}$ for a classification problem with $K$ possible labels.
From the multiple answers, we can compute the frequency of each answers per label denoted $\hat y_i^{\mathrm{NS}}=\mathrm{NS}({y_i^{(j)}}<em>{j\in n</em>{\text{worker}}})$.</p>

\[\forall x_i,\ \mathrm{Ent}(x_i) = -\sum_{k\in[K]} \hat{y_{i, k}^{\mathrm{NS}}} \log\left(\hat{y_{i, k}^{\mathrm{NS}}}\right) \enspace.\]

<h2 id="cli">CLI</h2>

<p>For a classification problem, with $K=10$, if the json file of answers is located at the current directory simply run:</p>

<pre><code class="language-{bash}">peerannot identify . -s entropy -K 10
</code></pre>

<p>This creates a file named <code class="language-plaintext highlighter-rouge">entropy.npy</code> saved in the <code class="language-plaintext highlighter-rouge">./identification</code> folder.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="identification" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Simulate labels with hammer-spammer</title><link href="https://github.com/pages/peerannot/peerannot/datasets/simulate_hammer_spammer/" rel="alternate" type="text/html" title="Simulate labels with hammer-spammer" /><published>2023-08-08T00:00:00+00:00</published><updated>2023-08-08T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/datasets/hammer_spammer</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/datasets/simulate_hammer_spammer/"><![CDATA[<p>This is an example of simulation using the <code class="language-plaintext highlighter-rouge">peerannot</code> library that considers the hammer-spammer setting.</p>

<h2 id="discrete-difficulty-simulation">Discrete-difficulty simulation</h2>

<p>Each task is assigned a true label $y_i^\star$.
Each worker is either a spammer or a hammer</p>
<ul>
  <li>If worker is a hammer, they answer correctly: $y_i^{(j)}=y_i^\star$</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>If the worker is a spammer, they answer uniformly a label over the range of possibilities: $\forall k,\ell\in[K]^2, \ \mathbb{P}(y_i^{(j)}=k</td>
          <td>y_i^\star=\ell)=K^{-1}$.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="run-the-simulation">Run the simulation</h3>

<p>Let us run a simulation with $n_{\texttt{worker}}=30$ workers, $n_{\texttt{task}}=100$ tasks with $K=3$ classes.
Each task receives a random number of votes between $1$ and $n_{\texttt{worker}}$ using the key <code class="language-plaintext highlighter-rouge">imbalance-votes</code></p>

<p>The maximum number of tasks per worker / label per task can be modified using <code class="language-plaintext highlighter-rouge">workerload</code>/<code class="language-plaintext highlighter-rouge">feedback</code> parameters.</p>

<p>Results are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_hammer_spammer</code>.
The number of spammers and hammers is controlled with the parameter <code class="language-plaintext highlighter-rouge">ratio</code> which indicates the number of spammers over the number of hammers.
We set the <code class="language-plaintext highlighter-rouge">seed</code> to $3$ for reproducibility.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot simulate <span class="nt">--n-worker</span><span class="o">=</span>30 <span class="nt">--n-task</span><span class="o">=</span>100 <span class="nt">--n-classes</span><span class="o">=</span>3 <span class="nt">--strategy</span> hammer-spammer <span class="nt">--imbalance-votes</span> <span class="nt">--seed</span><span class="o">=</span>3 <span class="nt">--folder</span> ./temp/test_hammer_spammer
</code></pre></div></div>

<p>Confusion matrices for each worker are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_hammer_spammer</code> to help further analysis.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="datasets" /><category term="simulate" /><summary type="html"><![CDATA[Simulate with hammer-spammer in peerannot]]></summary></entry><entry><title type="html">CrowdLayer</title><link href="https://github.com/pages/peerannot/peerannot/models/crowdlayer/" rel="alternate" type="text/html" title="CrowdLayer" /><published>2023-08-08T00:00:00+00:00</published><updated>2023-08-08T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/crowdlayer</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/crowdlayer/"><![CDATA[<h2 id="crowdlayer-rodrigues-et-al-2018">Crowdlayer (Rodrigues et. al 2018)</h2>

<p>Given the output $z_i=\mathcal{C}(x_i)$, CrowdLayer introduce worker specific noise as an added layer to the network such that</p>

<p>\(\mathcal{L}(x_i) = \sum_{j} CE(h_i^{(j)}, y_i^{(j)})\)
with
\(h_i^{(j)} = \pi^{(j)}\sigma(z_i).\)</p>

<p>The weights in the added layer act as the confusion matrices from the Dawid and Skene model.</p>

<h2 id="cli-example">CLI example</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot aggregate-deep <span class="nb">.</span> <span class="nt">-o</span> my_output <span class="nt">--answers</span> ./answers.json <span class="nt">-s</span> crowdlayer <span class="nt">--model</span> resnet18 <span class="se">\</span>
          <span class="nt">--img-size</span><span class="o">=</span>224 <span class="nt">--pretrained</span> <span class="nt">--n-classes</span><span class="o">=</span>K <span class="nt">--n-epochs</span><span class="o">=</span>100 <span class="nt">--lr</span><span class="o">=</span>0.001 <span class="se">\</span>
          <span class="nt">-m</span> 50 <span class="nt">-m</span> 75 <span class="nt">--scheduler</span><span class="o">=</span>multistep <span class="nt">--batch-size</span><span class="o">=</span>228 <span class="nt">--optimizer</span><span class="o">=</span>adam <span class="se">\</span>
          <span class="nt">--num-workers</span><span class="o">=</span>8 <span class="nt">--data-augmentation</span> <span class="nt">--seed</span><span class="o">=</span>1
</code></pre></div></div>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="agg_deep" /><category term="Crowdlayer" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">CoNAL</title><link href="https://github.com/pages/peerannot/peerannot/models/CoNAL/" rel="alternate" type="text/html" title="CoNAL" /><published>2023-06-22T00:00:00+00:00</published><updated>2023-06-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/CoNAL</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/CoNAL/"><![CDATA[<h2 id="learning-from-common-confusions-chu-et-al-2021">Learning from common confusions Chu et. al 2021</h2>

<p>Given the output $z_i=\mathcal{C}(x_i)$, CoNAL interpolates between local confusions $\pi^{(j)}$ and global confusions $\pi^g$ as follows:
\(\mathcal{L}(x_i) = \sum_{j} CE(h_i^{(j)}, y_i^{(j)})\)
with
\(h_i^{(j)} = \sigma((w_i^{(j)}\pi^g + (1-w_i^{(j)})\pi^{(j)} )z_i).\)</p>

<p>The weight $w_i^{(j)}$ is computed from an auxiliary network that takes into account separately the worker in a vector $u_j$ and the task in a vector $v_i$ and
\(w_i^{(j)} = (1+\exp(-u_jv_i))^{-1}.\)</p>

<h2 id="cli">CLI</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot aggregate-deep <span class="nb">.</span> <span class="nt">-o</span> my_output <span class="nt">--answers</span> ./answers.json <span class="nt">-s</span> CoNAL[scale<span class="o">=</span>0] <span class="nt">--model</span> resnet18 <span class="se">\</span>
          <span class="nt">--img-size</span><span class="o">=</span>224 <span class="nt">--pretrained</span> <span class="nt">--n-classes</span><span class="o">=</span>K <span class="nt">--n-epochs</span><span class="o">=</span>100 <span class="nt">--lr</span><span class="o">=</span>0.001 <span class="se">\</span>
          <span class="nt">-m</span> 50 <span class="nt">-m</span> 75 <span class="nt">--scheduler</span><span class="o">=</span>multistep <span class="nt">--batch-size</span><span class="o">=</span>228 <span class="nt">--optimizer</span><span class="o">=</span>adam <span class="se">\</span>
          <span class="nt">--num-workers</span><span class="o">=</span>8 <span class="nt">--data-augmentation</span> <span class="nt">--seed</span><span class="o">=</span>1
</code></pre></div></div>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="agg_deep" /><category term="CONAL" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">WAUM</title><link href="https://github.com/pages/peerannot/peerannot/models/WAUM/" rel="alternate" type="text/html" title="WAUM" /><published>2023-06-22T00:00:00+00:00</published><updated>2023-06-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/WAUM</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/WAUM/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The Weighted Area Under the Margin (WAUM) allows identifying ambiguous tasks in crowdsourced datasets.
Given a neural network classifier $\mathcal{C}$ and a budget $T$ (number of epochs) and a task (image) $x_i$ with labels ${y_i^{(j)}}_{j\in\mathcal{A(x_i)}}$, the WAUM is defined as:</p>

\[\mathrm{WAUM}(x_i) := \frac{1}{|\mathcal{A}(x_i)|}\sum_{j\in\mathcal{A}(x_i)} s^{(j)}(x_i)\left\{\frac{1}{T}\sum_{t=1}^T  \sigma(\mathcal{C}(x_i))_{y_i^{(j)}} - \sigma(\mathcal{C}(x_i))_{[2]}\right\} \enspace.\]

<p>The weights $s^{(j)}(x_i)$ are defined as the dot-product between the diagonal of the DS confusion matrix and the probabilities output by the classifier.
In a separate file, tasks with WAUM under the quantile $q_\alpha$ are identified as potential ambiguities (with $\alpha\in]0,1[$).
The criterion optimized is the cross-entropy loss.</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the WAUM identification can be used as follows.
In this example, the classification is for 10 classes, using a pretrained Resnet18 network for $T=50$ epochs. The learning rate of the stochastic gradient descent is set to $0.01$.
The detection quantile is $q_{0.01}$.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot identify <span class="nb">.</span> <span class="nt">-s</span> WAUM <span class="nt">--n-classes</span> 10 <span class="nt">--model</span> resnet18  <span class="se">\</span>
                    <span class="nt">--n-epochs</span><span class="o">=</span>50 <span class="nt">--alpha</span><span class="o">=</span>0.01 <span class="nt">--lr</span><span class="o">=</span>0.01 <span class="se">\</span>
                    <span class="nt">--pretrained</span> <span class="nt">--optimizer</span><span class="o">=</span>sgd
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="identification" /><category term="WAUM" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Naive Soft</title><link href="https://github.com/pages/peerannot/peerannot/models/NaiveSoft/" rel="alternate" type="text/html" title="Naive Soft" /><published>2023-04-14T00:00:00+00:00</published><updated>2023-04-14T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/NaiveSoft</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/NaiveSoft/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The Naive Soft model returns the empirical distribution overs answered for each task:</p>

\[\DeclareMathOperator*{\argmax}{argmax}
\hat y_i = \big( \frac{1}{|n_\texttt{worker|}}\sum_{j\in [n_\texttt{worker}]}  \unicode{x1D7D9}_{\{y_i^{(j)}=k\}}\big).\]

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the DS model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> NaiveSoft <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">NaiveSoft</span> <span class="k">as</span> <span class="n">NS</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ns</span> <span class="o">=</span> <span class="n">NS</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">ns</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that the Naive Soft aggregation produces labels in the simplex by default.</p>

<h2 id="api-details-class-modelsnaivesoft">API details: class models.NaiveSoft</h2>
<p>NS model class inherits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionnary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">compute_baseline()</code></p>

<p>For each given task, computes the number of votes for each label.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_probas()</code></p>

<p>Returns the distribution of voted classes from the <code class="language-plaintext highlighter-rouge">baseline</code>.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="NS" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Clustered Dawid and Skene</title><link href="https://github.com/pages/peerannot/peerannot/models/DSWC/" rel="alternate" type="text/html" title="Clustered Dawid and Skene" /><published>2023-04-14T00:00:00+00:00</published><updated>2023-04-14T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/DSWC</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/DSWC/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The clustered Dawid and Skene model assumes that the answer is drawn from a multinomial distribution for each worker. This distribution is shared within each cluster.
The likelihood maximized is:</p>

<p>\(\mathbb{P}(\{y_i^{(j)}\}_{i,j}, \{y_i^\star\}_i, \pi|\rho,\tau,\Lambda) = \left[
  \prod_{i\in [n_\text{task}]} \prod_{j\in[n_\text{worker}]} \mathbb{P}(y_i^{(j)}|y_i^\star,\pi^{(j)})
\right] \left[\mathbb{P}(y_i^\star|\rho)\right]\left[\prod_{j\in [n_\text{worker}]} \mathbb{P}(\pi^{(j)}|\tau,\Lambda)\right]\enspace,\)
with $\rho_k=\mathbb{P}(y_i^\star=k)$ the prevalence prior and $\pi^{(j)}_{k,\bullet}$ the probabilities of the multinomial distribution for an answer with true label $k$.
The clustering factor comes up with the parameters $\tau$ and $\Lambda$.
The confusion matrix $\pi^{(j)}$ can take values in $\Lambda={\Lambda_1,\dots,\Lambda_L}$ the $L$ matrices defining clusters. Each matrix $\pi^{(j)}$ is equal to $\Lambda_k$ with probability $\tau_k$.
Hence, the confusion matrices follow a multinomial distribution over $\Lambda$ parametrized by $\tau$.</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the clustered DS model can be used as follows (for 3 clusters here).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> DSWC[L<span class="o">=</span>3] <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">Dawid_Skene_clust</span> <span class="k">as</span> <span class="n">DSWC</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dswc</span> <span class="o">=</span> <span class="n">DSWC</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dswc</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">dswc</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="estimated-abilities">Estimated abilities</h3>

<p>To access the estimated confusion matrices in a variable <code class="language-plaintext highlighter-rouge">pi</code>, run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pi</span> <span class="o">=</span> <span class="n">dswc</span><span class="p">.</span><span class="n">pi_hat</span>
</code></pre></div></div>

<h2 id="api-details-class-modelsnaivesoft">API details: class models.NaiveSoft</h2>
<p>NS model class inherits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes, L=2, **kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">L=2</code>: <em>(int)</em>
Number of clusters for confusion matrices (must be lower or equal than the number of workers)</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.
Must contain the number of workers <code class="language-plaintext highlighter-rouge">n_workers</code>.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">run(epsilon=1e-4, maxiter=100)</code></p>

<p>Returns label estimates, confusion matrices, prevalence $\rho$ and number of iterations before the ELBO convergence between two iterates is satisfied.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_probas()</code></p>

<p>Returns the distribution of voted classes from the <code class="language-plaintext highlighter-rouge">baseline</code>.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="DSWC" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Simulate labels with difficulty</title><link href="https://github.com/pages/peerannot/peerannot/datasets/simulate_discrete_difficulty/" rel="alternate" type="text/html" title="Simulate labels with difficulty" /><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/datasets/difficulty</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/datasets/simulate_discrete_difficulty/"><![CDATA[<p>This is an example of simulation using the <code class="language-plaintext highlighter-rouge">peerannot</code> library that considers tasks’ difficulty.
The <code class="language-plaintext highlighter-rouge">discrete-difficulty</code> strategy simulates the following setting (here presented with $K=3$ classes for simplicity):</p>

<h2 id="discrete-difficulty-simulation">Discrete-difficulty simulation</h2>

<p>Each task is assigned a true label $y_i^\star$ and a difficulty level $d_i$ in $\{$ <code class="language-plaintext highlighter-rouge">easy</code>, <code class="language-plaintext highlighter-rouge">hard</code>, <code class="language-plaintext highlighter-rouge">random</code> $\}$. Each worker is either <code class="language-plaintext highlighter-rouge">good</code> of <code class="language-plaintext highlighter-rouge">bad</code></p>
<ul>
  <li>If the task is <code class="language-plaintext highlighter-rouge">easy</code>, every worker answers correctly: $y_i^{(j)}=y_i^\star$</li>
  <li>If the task is <code class="language-plaintext highlighter-rouge">random</code>, every worker answers randomly: $\mathbb{P}(y_i^{(j)}=m\vert y_i^\star=k) = \frac{1}{K}$.</li>
  <li>If the task is <code class="language-plaintext highlighter-rouge">hard</code>, each worker $w_j$ is assigned a confusion matrix $\pi^{(j)}$ where $\pi^{(j)}_{k,m} = \mathbb{P}(y_i^{(j)}=m\vert y_i^\star=k)$:
    <ul>
      <li>if the worker is <code class="language-plaintext highlighter-rouge">good</code>, each row of the confusion matrix is simulated using a $\mathcal{D}\text{irichlet}(\alpha=[0.2, 0.2, 0.2])$ with maximum located at $y_i^\star$</li>
      <li>if the worker is <code class="language-plaintext highlighter-rouge">bad</code> each row of the confusion matrix is simulated using a $\mathcal{D}\text{irichlet}(\alpha=[1, 1, 1])$, <em>i.e.</em> the uniform distribution over the simplex.
The final answer is then drawn from the Multinomial $\big(\pi^{(j)}_{y_i^\star, \bullet}\big)$</li>
    </ul>
  </li>
</ul>

<p>If you have a worker of profile fixed that does not rely on Dirichlet distributions, <code class="language-plaintext highlighter-rouge">peerannot</code> works too!
Simply store your confusion matrices in an <code class="language-plaintext highlighter-rouge">.npy</code> file containing an <code class="language-plaintext highlighter-rouge">np.ndarray</code> of shape <code class="language-plaintext highlighter-rouge">(n_worker, K, K)</code> and then use the <code class="language-plaintext highlighter-rouge">--matrix-file_path_to_matrix_file.npy</code> argument to use your own confusion matrices.</p>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-dirichlet-densities-output-1.png" id="fig-dirichlet-densities" class="margin-caption" alt="Figure 1: 3000 draws of the Dirichlet distributions for good (left) and bad (right) workers" />
<figcaption aria-hidden="true">Figure 1: 3000 draws of the Dirichlet
distributions for good (left) and bad (right) workers</figcaption>
</figure>

<h3 id="run-the-simulation">Run the simulation</h3>

<p>Let us run a simulation with $n_{\texttt{worker}}=30$ workers, $n_{\texttt{task}}=100$ tasks with $K=3$ classes.
Each task receives a random number of votes between $1$ and $n_{\texttt{worker}}$ using the key <code class="language-plaintext highlighter-rouge">imbalance-votes</code></p>

<p>The maximum number of tasks per worker / label per task can be modified using <code class="language-plaintext highlighter-rouge">workerload</code>/<code class="language-plaintext highlighter-rouge">feedback</code> parameters.</p>

<p>Results are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_discrete_difficulty</code>.
There are $0.7\cdot n_{\texttt{worker}}$ <code class="language-plaintext highlighter-rouge">good</code> workers.
The probability for a task to be <code class="language-plaintext highlighter-rouge">random</code> is set to $p_{\text{random}}=0.3$, and the ratio of <code class="language-plaintext highlighter-rouge">good</code> over <code class="language-plaintext highlighter-rouge">hard</code> tasks is set to $r=0.4$ <em>i.e.</em> the choice between <code class="language-plaintext highlighter-rouge">easy</code>, <code class="language-plaintext highlighter-rouge">hard</code> and <code class="language-plaintext highlighter-rouge">random</code> difficulty $d_i$ follows:</p>

\[d_i \sim \mathcal{M}\text{ultinomial}\bigg(
  1- p_{\text{random}} -  \frac{1-p_{\text{random}}}{r+1}, \frac{1- p_{\text{random}}}{r+1}, p_{\text{random}}
  \bigg) \enspace.\]

<p>We set the <code class="language-plaintext highlighter-rouge">seed</code> to $3$ for reproducibility.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>peerannot simulate <span class="nt">--n-worker</span> 30 <span class="nt">--n-task</span> 100  <span class="nt">-K</span> 3 <span class="se">\</span>
                    <span class="nt">-s</span> discrete-difficulty <span class="se">\</span>
                    <span class="nt">--folder</span> ./temp/test_discrete_difficulty/ <span class="se">\</span>
                    <span class="nt">-r</span> 0.7 <span class="nt">--ratio-diff</span> 0.4 <span class="nt">--random</span> 0.3 <span class="se">\</span>
                    <span class="nt">--imbalance-votes</span> <span class="se">\</span>
                    <span class="nt">--seed</span> 5<span class="p">;</span>
</code></pre></div></div>

<h2 id="explore-results">Explore results</h2>

<h3 id="workers-answers">Workers’ answers</h3>

<p>The simulation created the dictionary of answers for each task and worker in <code class="language-plaintext highlighter-rouge">answers.json</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="n">dir_</span> <span class="o">=</span> <span class="n">Path</span><span class="p">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s">"temp"</span> <span class="o">/</span> <span class="s">"test_discrete_difficulty"</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"answers.json"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">all_ans</span><span class="p">:</span>
    <span class="n">answers</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">all_ans</span><span class="p">)</span>  <span class="c1"># warning: keys are string
</span><span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"ground_truth.npy"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
  <span class="s">"votes_repartition"</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">.</span><span class="n">values</span><span class="p">()]</span>
  <span class="p">},</span> <span class="n">x</span><span class="o">=</span><span class="s">"votes_repartition"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">5</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feedback"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-repartition-output-1.png" id="fig-repartition" class="margin-caption" alt="Figure 2: Number of labels per task" />
<figcaption aria-hidden="true">Figure 2: Number of labels per
task</figcaption>
</figure>

<h3 id="task-difficulty">Task difficulty</h3>

<p>The difficulty of each task is accessible in <code class="language-plaintext highlighter-rouge">difficulties.npy</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"whitegrid"</span><span class="p">)</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"difficulties.npy"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">"difficulty"</span><span class="p">:</span> <span class="n">diff</span><span class="p">},</span> <span class="n">x</span><span class="o">=</span><span class="s">"difficulty"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-difficulties-output-1.png" id="fig-difficulties" class="margin-caption" alt="Figure 3: Repartition of difficulties in the simulated tasks" />
<figcaption aria-hidden="true">Figure 3: Repartition of difficulties in
the simulated tasks</figcaption>
</figure>

<h3 id="confusion-matrices">Confusion matrices</h3>

<p>Finally, confusion matrices $\pi^{(j)}$ are stored in <code class="language-plaintext highlighter-rouge">matrices.npy</code>.</p>

<p>The confusion matrix of a good worker is always diagonally dominant.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"matrices.npy"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">".2f"</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="mi">28</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">".2f"</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Good worker $w_1$"</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Bad worker $w_{28}$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-confusion-output-1.png" id="fig-confusion" class="margin-caption" alt="Figure 4: Confusion matrix of a good worker (left) and a bac worker (right)" />
<figcaption aria-hidden="true">Figure 4: Confusion matrix of a good
worker (left) and a bad worker (right)</figcaption>
</figure>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="datasets" /><category term="simulate" /><summary type="html"><![CDATA[Simulate with difficulty in peerannot]]></summary></entry><entry><title type="html">Majority voting</title><link href="https://github.com/pages/peerannot/peerannot/models/MV/" rel="alternate" type="text/html" title="Majority voting" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/MV</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/MV/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The Majority voting model returns the most voted label among the $K$ labels, for each task:</p>

\[\DeclareMathOperator*{\argmax}{argmax}
\hat y_i = \argmax_{k\in[K]} \sum_{j\in [n_\texttt{worker}]}  \unicode{x1D7D9}_{\{y_i^{(j)}=k\}}.\]

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the MV model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> MV <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">MV</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mv</span> <span class="o">=</span> <span class="n">MV</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">mv</span><span class="p">.</span><span class="n">get_answers</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that the majority voting aggregation produces hard labels (Dirac distributions).</p>

<h2 id="api-details-class-modelsmv">API details: class models.MV</h2>
<p>MV model class inherits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">compute_baseline()</code></p>

<p>For each given task, computes the number of votes for each label.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="MV" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Generative model of Labels, Abilities, and Difficulties</title><link href="https://github.com/pages/peerannot/peerannot/models/GLAD/" rel="alternate" type="text/html" title="Generative model of Labels, Abilities, and Difficulties" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/GLAD</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/GLAD/"><![CDATA[<h2 id="model">Model</h2>

<p>GLAD’s model models both the worker ability and task difficulty into the label aggregation scheme. In order to do so, we write $\alpha_j\in\mathbb{R}$ the worker ability and $\beta_i\in\mathbb{R}^+_\star$ the task difficulty.</p>

<p>The model is as follows:</p>

\[\mathbb{P}\bigg(y_i^{(j)}=y_i^\star\bigg)=\frac{1}{1+e^{-\alpha_j\beta_i}}.\]

<p>We also assume that the error is uniform elsewhere, <em>i.e.</em> in a classification setting with $K$ classes that
\(\mathbb{P}\bigg(y_i^{(j)}\neq y_i^\star\bigg)=\frac{1}{K-1}\bigg(1-\frac{1}{1+e^{-\alpha_j\beta_i}}\bigg).\)</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the GLAD model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> GLAD <span class="nt">--answers-file</span> answers.json <span class="nt">--</span>
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">GLAD</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glad</span> <span class="o">=</span> <span class="n">GLAD</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s">"glad"</span><span class="p">)</span>
<span class="n">glad</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>

<p>In the implementation, the prior on $(\alpha_j)_j$ and $(\beta_i)_i$ is set to a vector of ones.
This can be altered as follows for example with a prior on alphas of 2 and a prior on betas of 3:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glad</span> <span class="o">=</span> <span class="n">GLAD</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s">"glad"</span><span class="p">)</span>
<span class="n">glad</span><span class="p">.</span><span class="n">priorAlpha</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">glad</span><span class="p">.</span><span class="n">n_workers</span><span class="p">))</span>
<span class="n">glad</span><span class="p">.</span><span class="n">priorBeta</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">glad</span><span class="p">.</span><span class="n">n_task</span><span class="p">))</span>
<span class="n">glad</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="estimated-abilities">Estimated abilities</h3>

<p>To access the estimated confusion matrices in a variable <code class="language-plaintext highlighter-rouge">pi</code>, run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">beta</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">beta</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">alpha</span>
<span class="k">print</span><span class="p">(</span><span class="n">alpha</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">beta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (n_worker,) (n_task,)
</span></code></pre></div></div>

<h3 id="aggregate-into-hard-labels">Aggregate into hard labels</h3>

<p>After running the aggregation strategy, instead of soft labels one can recover hard labels by running:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yhat_hard</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">get_answers</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that this is an <code class="language-plaintext highlighter-rouge">argmax</code> on the first dimension with a random split in case of equalities.</p>

<h2 id="api-details-class-modelsglad">API details: class models.GLAD</h2>
<p>GLAD model class that herits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that should contain at least <code class="language-plaintext highlighter-rouge">n_workers</code> the number of workers.
Other arguments are <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">EM(epsilon, maxiter)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">epsilon</code>: <em>(float)</em> relative error between two iterates of the expectation of the joint likelihood</li>
  <li><code class="language-plaintext highlighter-rouge">maxiter</code>: <em>(int)</em> maximum number of iterations in the EM algorithm</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">run(epsilon, maxiter)</code></p>

<p>Run the EM algorithm for a given set of parameters</p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">epsilon</code>: <em>(float)</em> relative error between two iterates of the expectation of the joint likelihood</li>
  <li><code class="language-plaintext highlighter-rouge">maxiter</code>: <em>(int)</em> maximum number of iterations in the EM algorithm</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">save_difficulty(path)</code></p>

<p>Save coefficients $(\beta)_i$ at a given path as <code class="language-plaintext highlighter-rouge">numpy</code> arrays.</p>

<p>Parameters:</p>
<ul>
  <li>path: <em>(str)</em> file path in which coefficients are saved using the <code class="language-plaintext highlighter-rouge">np.save</code> function.</li>
</ul>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="GLAD" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry></feed>