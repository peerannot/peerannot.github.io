<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://github.com/pages/peerannot/peerannot/feed.xml" rel="self" type="application/atom+xml" /><link href="https://github.com/pages/peerannot/peerannot/" rel="alternate" type="text/html" /><updated>2023-10-25T08:10:52+00:00</updated><id>https://github.com/pages/peerannot/peerannot/feed.xml</id><title type="html">Peerannot</title><subtitle>Handling your crowdsourced datasets</subtitle><entry><title type="html">Krippendorff’s Alpha</title><link href="https://github.com/pages/peerannot/peerannot/models/KrippendorffAlpha/" rel="alternate" type="text/html" title="Krippendorff’s Alpha" /><published>2023-10-03T00:00:00+00:00</published><updated>2023-10-03T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/Krippendorff</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/KrippendorffAlpha/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The Krippendorff’s Alpha coefficient identification measures the agreement between workers on the labels answered to a dataset.</p>

<ul>
  <li>A dataset with $\alpha = 1$ has a perfect reliability.</li>
  <li>A dataset with $\alpha = 0$ has no reliability, task and labels are statistically unrelated.</li>
  <li>A dataset with $\alpha &lt; 0$ has a systematics disagreement, more than what can be expected by chance.</li>
</ul>

<p>We can compute the Krippenderoff’s alpha coefficient as:</p>

\[\alpha = 1 - \frac{D_o}{D_e} \enspace.\]

<p>Where $D_o$ is the disagreement observed and $D_e$ is the disagreement expected by chance.
We define as \(\mathcal{L}(x_i)\) the vector of labels given to the task $x_i \in \mathcal{X}$: \(\mathcal{L}(x_i) = (y_i^{(j)})_{j \in \mathcal{A}(x_i)}\)</p>

\[D_o = \frac{1}{n_{\text{worker}}}\sum_{x_i \in \mathcal{X}}\sum_{k \in \mathcal{L}(x_i)}\sum_{k' \in \mathcal{L}(x_i)}\delta(k,k')\frac{1}{|\mathcal{L}(x_i)|-1} \enspace,\]

\[D_e = \frac{1}{ n_{\text{task}}(n_{\text{task}}-1)}\sum_{x_i \in \mathcal{X}}\sum_{k \in \mathcal{L}(x_i)}\sum_{k' \in \mathcal{L}(x_i)}\delta(k,k') \enspace,\]

<p>Where $\delta$ is a metric function, for our case we use the discrete distance defined as :</p>

\[\begin{equation}
  \delta(v,v') = 
    \begin{cases}
      0 &amp; \text{if $v$ = $v'$}\\
      1 &amp; \text{if $v \neq v'$}
    \end{cases} 
\enspace.
\end{equation}\]

<h2 id="cli">CLI</h2>

<p>For a classification problem, if the json file of answers is located at the current directory simply run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot identify <span class="nb">.</span> <span class="nt">-s</span> krippendorffalpha
</code></pre></div></div>

<p>This creates a file named <code class="language-plaintext highlighter-rouge">krippendorff_alpha.npy</code> saved in the <code class="language-plaintext highlighter-rouge">./identification</code> folder.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Spam score</title><link href="https://github.com/pages/peerannot/peerannot/models/spam_score/" rel="alternate" type="text/html" title="Spam score" /><published>2023-08-09T00:00:00+00:00</published><updated>2023-08-09T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/spam-score</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/spam_score/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The spam score was introduced by Raykar et. al (2012).
A spammer can be defined as someone answered independently of the true label <em>i.e.</em></p>

\[\mathbb{P}(y_i^{(j)}=k\ |\ y_i^\star =\ell) = \mathbb{P}(y_i^{(j)}=k\ | y_i^\star =\ell')\ \forall (k,\ell, \ell') \in [K]^3.\]

<p>Let $\alpha_{\ell k}^{(j)} = \mathbb{P}(y_i^{(j)}=k\ |\ y_i^\star =\ell)$.
Then for a spammer $\alpha_{\ell k}^{(j)} = \alpha_{\ell’ k}^{(j)}\ \forall (k,\ell,\ell’) \in [K]^3$.
We can store them in a confusion matrix $ \pi^{(j)}\in\mathbb{R}^{K\times K} $ such that $ \pi^{(j)}<em>{\ell,k}=\alpha^{(j)}</em>{\ell,k} $.</p>

<p>A perfect spammer will have equal rows, leading to a matrix of rank $1$.
The spam score $s^{(j)}$ is thus defined as the distance to the closest rank one approximation of the confusion matrix $\pi^{(j)}$.
More formally:</p>

\[s^{(j)} = \|\pi^{(j)} - e\hat v_j^\top \|_F^2 \quad \text{s.t } \hat v_j = \arg\min_{v_j} \|\pi^{(j)}-ev_j^\top \|_F^2,\ v_j^\top e=1 \enspace.\]

<p>Solving this optimization problem, we obtain that a perfect worker has $s^{(j)}=K-1$. We can normalize the scores and obtain the following explicit formula:</p>

\[s^{(j)}= \frac{1}{K(K-1)} \sum_{\ell\leq \ell'} \sum_k (\alpha^{(j)}_{\ell,k} - \alpha^{(j)}_{\ell',k})^2 \enspace.\]

<h2 id="cli">CLI</h2>

<p>To run the spammer identification in a classification problem with $K=10$ classes, we use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot identify <span class="nb">.</span> <span class="nt">-s</span> spam_score <span class="nt">-K</span> 10
</code></pre></div></div>

<p>Label file can be modified using the argument <code class="language-plaintext highlighter-rouge">--labels=&lt;new_path_to_json_file&gt;</code>.
Spam scores are stored in the folder <code class="language-plaintext highlighter-rouge">./identification</code> in the <code class="language-plaintext highlighter-rouge">spam_score.npy</code> file.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Weighted with Dawid and Skene</title><link href="https://github.com/pages/peerannot/peerannot/models/WDS/" rel="alternate" type="text/html" title="Weighted with Dawid and Skene" /><published>2023-08-09T00:00:00+00:00</published><updated>2023-08-09T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/wds</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/WDS/"><![CDATA[<h2 id="model">Model</h2>

<p>Following the [DS][/models/DS] model, one can use the diagonal of the estimated confusion matrices ${\pi^{(j)}}<em>{j\in [n</em>\text{worker}]}$ to create a weighted soft label as follows:</p>

\[\hat y_i^{\mathrm{WDS}} = \mathrm{Norm}\left(\sum_{j\in [n_\text{worker}]} \pi^{(j)}_{k,k} \unicode{x1D7D9}_{\\{y_i^{\star}=k \\}} \right)_{k\in[K]} \enspace,\]

<p>with $\mathrm{Norm}(z)= \left( \frac{z_k}{\sum_{k’\in[K]} z_{k’}}\right)_{k\in[K]}$.</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the DS model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> WDS <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Entropy</title><link href="https://github.com/pages/peerannot/peerannot/models/entropy/" rel="alternate" type="text/html" title="Entropy" /><published>2023-08-09T00:00:00+00:00</published><updated>2023-08-09T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/entropy</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/entropy/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The entropy measures how diverse the labels answered to a given task are.
With enough labels, tasks with high entropy can be identified as potential ambiguities/difficulties.
A task with a null-entropy has reached perfect consensus.</p>

<p>More formally, let task $x_i\in\mathcal{X}$ for a classification problem with $K$ possible labels.
From the multiple answers, we can compute the frequency of each answers per label denoted</p>

<p>\(\hat{y_i^{\mathrm{NS}}}=\mathrm{NS}(\{y_i^{(j)}\}_{j\in [n_\text{worker}]}) \enspace.\)
The entropy can then be written:
\(\forall x_i,\ \mathrm{Ent}(x_i) = -\sum_{k\in[K]} \hat{y_{i, k}^{\mathrm{NS}}} \log\left(\hat{y_{i, k}^{\mathrm{NS}}}\right) \enspace.\)</p>

<h2 id="cli">CLI</h2>

<p>For a classification problem, with $K=10$, if the json file of answers is located at the current directory simply run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot identify <span class="nb">.</span> <span class="nt">-s</span> entropy <span class="nt">-K</span> 10
</code></pre></div></div>

<p>This creates a file named <code class="language-plaintext highlighter-rouge">entropy.npy</code> saved in the <code class="language-plaintext highlighter-rouge">./identification</code> folder.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">CrowdLayer</title><link href="https://github.com/pages/peerannot/peerannot/models/crowdlayer/" rel="alternate" type="text/html" title="CrowdLayer" /><published>2023-08-08T00:00:00+00:00</published><updated>2023-08-08T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/crowdlayer</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/crowdlayer/"><![CDATA[<h2 id="crowdlayer-rodrigues-et-al-2018">Crowdlayer (Rodrigues et. al 2018)</h2>

<p>Given the output $z_i=\mathcal{C}(x_i)$, CrowdLayer introduce worker specific noise as an added layer to the network such that</p>

<p>\(\mathcal{L}(x_i) = \sum_{j} CE(h_i^{(j)}, y_i^{(j)})\)
with
\(h_i^{(j)} = \pi^{(j)}\sigma(z_i).\)</p>

<p>The weights in the added layer act as the confusion matrices from the Dawid and Skene model.</p>

<h2 id="cli-example">CLI example</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot aggregate-deep <span class="nb">.</span> <span class="nt">-o</span> my_output <span class="nt">--answers</span> ./answers.json <span class="nt">-s</span> crowdlayer <span class="nt">--model</span> resnet18 <span class="se">\</span>
          <span class="nt">--img-size</span><span class="o">=</span>224 <span class="nt">--pretrained</span> <span class="nt">--n-classes</span><span class="o">=</span>K <span class="nt">--n-epochs</span><span class="o">=</span>100 <span class="nt">--lr</span><span class="o">=</span>0.001 <span class="se">\</span>
          <span class="nt">-m</span> 50 <span class="nt">-m</span> 75 <span class="nt">--scheduler</span><span class="o">=</span>multistep <span class="nt">--batch-size</span><span class="o">=</span>228 <span class="nt">--optimizer</span><span class="o">=</span>adam <span class="se">\</span>
          <span class="nt">--num-workers</span><span class="o">=</span>8 <span class="nt">--data-augmentation</span> <span class="nt">--seed</span><span class="o">=</span>1
</code></pre></div></div>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Simulate labels with hammer-spammer</title><link href="https://github.com/pages/peerannot/peerannot/datasets/simulate_hammer_spammer/" rel="alternate" type="text/html" title="Simulate labels with hammer-spammer" /><published>2023-08-08T00:00:00+00:00</published><updated>2023-08-08T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/datasets/hammer_spammer</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/datasets/simulate_hammer_spammer/"><![CDATA[<p>This is an example of simulation using the <code class="language-plaintext highlighter-rouge">peerannot</code> library that considers the hammer-spammer setting.</p>

<h2 id="discrete-difficulty-simulation">Discrete-difficulty simulation</h2>

<p>Each task is assigned a true label $y_i^\star$.
Each worker is either a spammer or a hammer</p>
<ul>
  <li>If worker is a hammer, they answer correctly: $y_i^{(j)}=y_i^\star$</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>If the worker is a spammer, they answer uniformly a label over the range of possibilities: $\forall k,\ell\in[K]^2, \ \mathbb{P}(y_i^{(j)}=k</td>
          <td>y_i^\star=\ell)=K^{-1}$.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="run-the-simulation">Run the simulation</h3>

<p>Let us run a simulation with $n_{\texttt{worker}}=30$ workers, $n_{\texttt{task}}=100$ tasks with $K=3$ classes.
Each task receives a random number of votes between $1$ and $n_{\texttt{worker}}$ using the key <code class="language-plaintext highlighter-rouge">imbalance-votes</code></p>

<p>The maximum number of tasks per worker / label per task can be modified using <code class="language-plaintext highlighter-rouge">workerload</code>/<code class="language-plaintext highlighter-rouge">feedback</code> parameters.</p>

<p>Results are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_hammer_spammer</code>.
The number of spammers and hammers is controlled with the parameter <code class="language-plaintext highlighter-rouge">ratio</code> which indicates the number of spammers over the number of hammers.
We set the <code class="language-plaintext highlighter-rouge">seed</code> to $3$ for reproducibility.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot simulate <span class="nt">--n-worker</span><span class="o">=</span>30 <span class="nt">--n-task</span><span class="o">=</span>100 <span class="nt">--n-classes</span><span class="o">=</span>3 <span class="nt">--strategy</span> hammer-spammer <span class="nt">--imbalance-votes</span> <span class="nt">--seed</span><span class="o">=</span>3 <span class="nt">--folder</span> ./temp/test_hammer_spammer
</code></pre></div></div>

<p>Confusion matrices for each worker are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_hammer_spammer</code> to help further analysis.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="datasets" /><category term="simulate" /><summary type="html"><![CDATA[Simulate with hammer-spammer in peerannot]]></summary></entry><entry><title type="html">CoNAL</title><link href="https://github.com/pages/peerannot/peerannot/models/CoNAL/" rel="alternate" type="text/html" title="CoNAL" /><published>2023-06-22T00:00:00+00:00</published><updated>2023-06-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/CoNAL</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/CoNAL/"><![CDATA[<h2 id="learning-from-common-confusions-chu-et-al-2021">Learning from common confusions Chu et. al 2021</h2>

<p>Given the output $z_i=\mathcal{C}(x_i)$, CoNAL interpolates between local confusions $\pi^{(j)}$ and global confusions $\pi^g$ as follows:
\(\mathcal{L}(x_i) = \sum_{j} CE(h_i^{(j)}, y_i^{(j)})\)
with
\(h_i^{(j)} = \sigma((w_i^{(j)}\pi^g + (1-w_i^{(j)})\pi^{(j)} )z_i).\)</p>

<p>The weight $w_i^{(j)}$ is computed from an auxiliary network that takes into account separately the worker in a vector $u_j$ and the task in a vector $v_i$ and
\(w_i^{(j)} = (1+\exp(-u_jv_i))^{-1}.\)</p>

<h2 id="cli">CLI</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot aggregate-deep <span class="nb">.</span> <span class="nt">-o</span> my_output <span class="nt">--answers</span> ./answers.json <span class="nt">-s</span> CoNAL[scale<span class="o">=</span>0] <span class="nt">--model</span> resnet18 <span class="se">\</span>
          <span class="nt">--img-size</span><span class="o">=</span>224 <span class="nt">--pretrained</span> <span class="nt">--n-classes</span><span class="o">=</span>K <span class="nt">--n-epochs</span><span class="o">=</span>100 <span class="nt">--lr</span><span class="o">=</span>0.001 <span class="se">\</span>
          <span class="nt">-m</span> 50 <span class="nt">-m</span> 75 <span class="nt">--scheduler</span><span class="o">=</span>multistep <span class="nt">--batch-size</span><span class="o">=</span>228 <span class="nt">--optimizer</span><span class="o">=</span>adam <span class="se">\</span>
          <span class="nt">--num-workers</span><span class="o">=</span>8 <span class="nt">--data-augmentation</span> <span class="nt">--seed</span><span class="o">=</span>1
</code></pre></div></div>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">WAUM</title><link href="https://github.com/pages/peerannot/peerannot/models/WAUM/" rel="alternate" type="text/html" title="WAUM" /><published>2023-06-22T00:00:00+00:00</published><updated>2023-06-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/WAUM</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/WAUM/"><![CDATA[<h2 id="identification-step">Identification step</h2>

<p>The Weighted Area Under the Margin (WAUM) allows identifying ambiguous tasks in crowdsourced datasets.
Given a neural network classifier $\mathcal{C}$ and a budget $T$ (number of epochs) and a task (image) $x_i$ with labels ${y_i^{(j)}}_{j\in\mathcal{A(x_i)}}$, the WAUM is defined as:</p>

\[\mathrm{WAUM}(x_i) := \frac{1}{|\mathcal{A}(x_i)|}\sum_{j\in\mathcal{A}(x_i)} s^{(j)}(x_i)\left\{\frac{1}{T}\sum_{t=1}^T  \sigma(\mathcal{C}(x_i))_{y_i^{(j)}} - \sigma(\mathcal{C}(x_i))_{[2]}\right\} \enspace.\]

<p>The weights $s^{(j)}(x_i)$ are defined as the dot-product between the diagonal of the DS confusion matrix and the probabilities output by the classifier.
In a separate file, tasks with WAUM under the quantile $q_\alpha$ are identified as potential ambiguities (with $\alpha\in]0,1[$).
The criterion optimized is the cross-entropy loss.</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the WAUM identification can be used as follows.
In this example, the classification is for 10 classes, using a pretrained Resnet18 network for $T=50$ epochs. The learning rate of the stochastic gradient descent is set to $0.01$.
The detection quantile is $q_{0.01}$.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannot identify <span class="nb">.</span> <span class="nt">-s</span> WAUM <span class="nt">--n-classes</span> 10 <span class="nt">--model</span> resnet18  <span class="se">\</span>
                    <span class="nt">--n-epochs</span><span class="o">=</span>50 <span class="nt">--alpha</span><span class="o">=</span>0.01 <span class="nt">--lr</span><span class="o">=</span>0.01 <span class="se">\</span>
                    <span class="nt">--pretrained</span> <span class="nt">--optimizer</span><span class="o">=</span>sgd
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Clustered Dawid and Skene</title><link href="https://github.com/pages/peerannot/peerannot/models/DSWC/" rel="alternate" type="text/html" title="Clustered Dawid and Skene" /><published>2023-04-14T00:00:00+00:00</published><updated>2023-04-14T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/DSWC</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/DSWC/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The clustered Dawid and Skene model assumes that the answer is drawn from a multinomial distribution for each worker. This distribution is shared within each cluster.
The likelihood maximized is:</p>

<p>\(\mathbb{P}(\{y_i^{(j)}\}_{i,j}, \{y_i^\star\}_i, \pi|\rho,\tau,\Lambda) = \left[
  \prod_{i\in [n_\text{task}]} \prod_{j\in[n_\text{worker}]} \mathbb{P}(y_i^{(j)}|y_i^\star,\pi^{(j)})
\right] \left[\mathbb{P}(y_i^\star|\rho)\right]\left[\prod_{j\in [n_\text{worker}]} \mathbb{P}(\pi^{(j)}|\tau,\Lambda)\right]\enspace,\)
with $\rho_k=\mathbb{P}(y_i^\star=k)$ the prevalence prior and $\pi^{(j)}_{k,\bullet}$ the probabilities of the multinomial distribution for an answer with true label $k$.
The clustering factor comes up with the parameters $\tau$ and $\Lambda$.
The confusion matrix $\pi^{(j)}$ can take values in $\Lambda={\Lambda_1,\dots,\Lambda_L}$ the $L$ matrices defining clusters. Each matrix $\pi^{(j)}$ is equal to $\Lambda_k$ with probability $\tau_k$.
Hence, the confusion matrices follow a multinomial distribution over $\Lambda$ parametrized by $\tau$.</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the clustered DS model can be used as follows (for 3 clusters here).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> DSWC[L<span class="o">=</span>3] <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">Dawid_Skene_clust</span> <span class="k">as</span> <span class="n">DSWC</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dswc</span> <span class="o">=</span> <span class="n">DSWC</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dswc</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">dswc</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="estimated-abilities">Estimated abilities</h3>

<p>To access the estimated confusion matrices in a variable <code class="language-plaintext highlighter-rouge">pi</code>, run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pi</span> <span class="o">=</span> <span class="n">dswc</span><span class="p">.</span><span class="n">pi_hat</span>
</code></pre></div></div>

<h2 id="api-details-class-modelsnaivesoft">API details: class models.NaiveSoft</h2>
<p>NS model class inherits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes, L=2, **kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">L=2</code>: <em>(int)</em>
Number of clusters for confusion matrices (must be lower or equal than the number of workers)</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.
Must contain the number of workers <code class="language-plaintext highlighter-rouge">n_workers</code>.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">run(epsilon=1e-4, maxiter=100)</code></p>

<p>Returns label estimates, confusion matrices, prevalence $\rho$ and number of iterations before the ELBO convergence between two iterates is satisfied.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_probas()</code></p>

<p>Returns the distribution of voted classes from the <code class="language-plaintext highlighter-rouge">baseline</code>.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Naive Soft</title><link href="https://github.com/pages/peerannot/peerannot/models/NaiveSoft/" rel="alternate" type="text/html" title="Naive Soft" /><published>2023-04-14T00:00:00+00:00</published><updated>2023-04-14T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/NaiveSoft</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/NaiveSoft/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The Naive Soft model returns the empirical distribution overs answered for each task:</p>

\[\DeclareMathOperator*{\argmax}{argmax}
\hat y_i = \big( \frac{1}{|n_\texttt{worker|}}\sum_{j\in [n_\texttt{worker}]}  \unicode{x1D7D9}_{\{y_i^{(j)}=k\}}\big).\]

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the DS model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> NaiveSoft <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">NaiveSoft</span> <span class="k">as</span> <span class="n">NS</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ns</span> <span class="o">=</span> <span class="n">NS</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">ns</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that the Naive Soft aggregation produces labels in the simplex by default.</p>

<h2 id="api-details-class-modelsnaivesoft">API details: class models.NaiveSoft</h2>
<p>NS model class inherits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionnary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href="/models/WAUM"><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">compute_baseline()</code></p>

<p>For each given task, computes the number of votes for each label.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_probas()</code></p>

<p>Returns the distribution of voted classes from the <code class="language-plaintext highlighter-rouge">baseline</code>.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry></feed>