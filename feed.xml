<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://github.com/pages/peerannot/peerannot/feed.xml" rel="self" type="application/atom+xml" /><link href="https://github.com/pages/peerannot/peerannot/" rel="alternate" type="text/html" /><updated>2023-03-06T10:33:40+00:00</updated><id>https://github.com/pages/peerannot/peerannot/feed.xml</id><title type="html">Peerannot</title><subtitle>Handling your crowdsourced datasets</subtitle><entry><title type="html">Simulate labels with difficulty</title><link href="https://github.com/pages/peerannot/peerannot/datasets/simulate_discrete_difficulty/" rel="alternate" type="text/html" title="Simulate labels with difficulty" /><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/datasets/difficulty</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/datasets/simulate_discrete_difficulty/"><![CDATA[<p>This is an example of simulation using the <code class="language-plaintext highlighter-rouge">peerannot</code> library that considers tasks’ difficulty.
The <code class="language-plaintext highlighter-rouge">discrete-difficulty</code> strategy simulates the following setting (here presented with $K=3$ classes for simplicity):</p>

<h2 id="discrete-difficulty-simulation">Discrete-difficulty simulation</h2>

<p>Each task is assigned a true label $y_i^\star$ and a difficulty level $d_i$ in $\{$ <code class="language-plaintext highlighter-rouge">easy</code>, <code class="language-plaintext highlighter-rouge">hard</code>, <code class="language-plaintext highlighter-rouge">random</code> $\}$. Each worker is either <code class="language-plaintext highlighter-rouge">good</code> of <code class="language-plaintext highlighter-rouge">bad</code></p>
<ul>
  <li>If the task is <code class="language-plaintext highlighter-rouge">easy</code>, every worker answers correctly: $y_i^{(j)}=y_i^\star$</li>
  <li>If the task is <code class="language-plaintext highlighter-rouge">random</code>, every worker answers randomly: $\mathbb{P}(y_i^{(j)}=m\vert y_i^\star=k) = \frac{1}{K}$.</li>
  <li>If the task is <code class="language-plaintext highlighter-rouge">hard</code>, each worker $w_j$ is assigned a confusion matrix $\pi^{(j)}$ where $\pi^{(j)}_{k,m} = \mathbb{P}(y_i^{(j)}=m\vert y_i^\star=k)$:
    <ul>
      <li>if the worker is <code class="language-plaintext highlighter-rouge">good</code>, each row of the confusion matrix is simulated using a $\mathcal{D}\text{irichlet}(\alpha=[0.2, 0.2, 0.2])$ with maximum located at $y_i^\star$</li>
      <li>if the worker is <code class="language-plaintext highlighter-rouge">bad</code> each row of the confusion matrix is simulated using a $\mathcal{D}\text{irichlet}(\alpha=[1, 1, 1])$, <em>i.e.</em> the uniform distribution over the simplex.
The final answer is then drawn from the Multinomial $\big(\pi^{(j)}_{y_i^\star, \bullet}\big)$</li>
    </ul>
  </li>
</ul>

<p>If you have a worker of profile fixed that does not rely on Dirichlet distributions, <code class="language-plaintext highlighter-rouge">peerannot</code> works too!
Simply store your confusion matrices in an <code class="language-plaintext highlighter-rouge">.npy</code> file containing an <code class="language-plaintext highlighter-rouge">np.ndarray</code> of shape <code class="language-plaintext highlighter-rouge">(n_worker, K, K)</code> and then use the <code class="language-plaintext highlighter-rouge">--matrix-file_path_to_matrix_file.npy</code> argument to use your own confusion matrices.</p>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-dirichlet-densities-output-1.png" id="fig-dirichlet-densities" class="margin-caption" alt="Figure 1: 3000 draws of the Dirichlet distributions for good (left) and bad (right) workers" />
<figcaption aria-hidden="true">Figure 1: 3000 draws of the Dirichlet
distributions for good (left) and bad (right) workers</figcaption>
</figure>

<h3 id="run-the-simulation">Run the simulation</h3>

<p>Let us run a simulation with $n_{\texttt{worker}}=30$ workers, $n_{\texttt{task}}=100$ tasks with $K=3$ classes.
Each task receives a random number of votes between $1$ and $n_{\texttt{worker}}$ using the key <code class="language-plaintext highlighter-rouge">imbalance-votes</code></p>

<p>The maximum number of tasks per worker / label per task can be modified using <code class="language-plaintext highlighter-rouge">workerload</code>/<code class="language-plaintext highlighter-rouge">feedback</code> parameters.</p>

<p>Results are stored in the folder <code class="language-plaintext highlighter-rouge">./temp/test_discrete_difficulty</code>.
There are $0.7\cdot n_{\texttt{worker}}$ <code class="language-plaintext highlighter-rouge">good</code> workers.
The probability for a task to be <code class="language-plaintext highlighter-rouge">random</code> is set to $p_{\text{random}}=0.3$, and the ratio of <code class="language-plaintext highlighter-rouge">good</code> over <code class="language-plaintext highlighter-rouge">hard</code> tasks is set to $r=0.4$ <em>i.e.</em> the choice between <code class="language-plaintext highlighter-rouge">easy</code>, <code class="language-plaintext highlighter-rouge">hard</code> and <code class="language-plaintext highlighter-rouge">random</code> difficulty $d_i$ follows:</p>

\[d_i \sim \mathcal{M}\text{ultinomial}\bigg(
  1- p_{\text{random}} -  \frac{1-p_{\text{random}}}{r+1}, \frac{1- p_{\text{random}}}{r+1}, p_{\text{random}}
  \bigg) \enspace.\]

<p>We set the <code class="language-plaintext highlighter-rouge">seed</code> to $3$ for reproducibility.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>peerannot simulate <span class="nt">--n-worker</span> 30 <span class="nt">--n-task</span> 100  <span class="nt">-K</span> 3 <span class="se">\</span>
                    <span class="nt">-s</span> discrete-difficulty <span class="se">\</span>
                    <span class="nt">--folder</span> ./temp/test_discrete_difficulty/ <span class="se">\</span>
                    <span class="nt">-r</span> 0.7 <span class="nt">--ratio-diff</span> 0.4 <span class="nt">--random</span> 0.3 <span class="se">\</span>
                    <span class="nt">--imbalance-votes</span> <span class="se">\</span>
                    <span class="nt">--seed</span> 5<span class="p">;</span>
</code></pre></div></div>

<h2 id="explore-results">Explore results</h2>

<h3 id="workers-answers">Workers’ answers</h3>

<p>The simulation created the dictionary of answers for each task and worker in <code class="language-plaintext highlighter-rouge">answers.json</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="n">dir_</span> <span class="o">=</span> <span class="n">Path</span><span class="p">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s">"temp"</span> <span class="o">/</span> <span class="s">"test_discrete_difficulty"</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"answers.json"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">all_ans</span><span class="p">:</span>
    <span class="n">answers</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">all_ans</span><span class="p">)</span>  <span class="c1"># warning: keys are string
</span><span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"ground_truth.npy"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
  <span class="s">"votes_repartition"</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">.</span><span class="n">values</span><span class="p">()]</span>
  <span class="p">},</span> <span class="n">x</span><span class="o">=</span><span class="s">"votes_repartition"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">5</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feedback"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-repartition-output-1.png" id="fig-repartition" class="margin-caption" alt="Figure 2: Number of labels per task" />
<figcaption aria-hidden="true">Figure 2: Number of labels per
task</figcaption>
</figure>

<h3 id="task-difficulty">Task difficulty</h3>

<p>The difficulty of each task is accessible in <code class="language-plaintext highlighter-rouge">difficulties.npy</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"whitegrid"</span><span class="p">)</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"difficulties.npy"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">"difficulty"</span><span class="p">:</span> <span class="n">diff</span><span class="p">},</span> <span class="n">x</span><span class="o">=</span><span class="s">"difficulty"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-difficulties-output-1.png" id="fig-difficulties" class="margin-caption" alt="Figure 3: Repartition of difficulties in the simulated tasks" />
<figcaption aria-hidden="true">Figure 3: Repartition of difficulties in
the simulated tasks</figcaption>
</figure>

<h3 id="confusion-matrices">Confusion matrices</h3>

<p>Finally, confusion matrices $\pi^{(j)}$ are stored in <code class="language-plaintext highlighter-rouge">matrices.npy</code>.</p>

<p>The confusion matrix of a good worker is always diagonally dominant.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">dir_</span> <span class="o">/</span> <span class="s">"matrices.npy"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">".2f"</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="mi">28</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">".2f"</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Good worker $w_1$"</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Bad worker $w_{28}$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<figure>
<img src="https://github.com/assets/quarto_files/build/simulate_discrete_difficulty_files/figure-commonmark/fig-confusion-output-1.png" id="fig-confusion" class="margin-caption" alt="Figure 4: Confusion matrix of a good worker (left) and a bac worker (right)" />
<figcaption aria-hidden="true">Figure 4: Confusion matrix of a good
worker (left) and a bad worker (right)</figcaption>
</figure>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="datasets" /><category term="simulate" /><summary type="html"><![CDATA[Simulate with difficulty in peerannot]]></summary></entry><entry><title type="html">Majority voting</title><link href="https://github.com/pages/peerannot/peerannot/models/MV/" rel="alternate" type="text/html" title="Majority voting" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/MV</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/MV/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/33302/double-struck-1-in-mathjax -->

<h2 id="model">Model</h2>

<p>The Majority voting model returns the most voted label among the $K$ labels, for each task:</p>

\[\DeclareMathOperator*{\argmax}{argmax}
\hat y_i = \argmax_{k\in[K]} \sum_{j\in [n_\texttt{worker}]}  \unicode{x1D7D9}_{\{y_i^{(j)}=k\}}.\]

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the DS model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> MV <span class="nt">--answers-file</span> DSanswers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">MV</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mv</span> <span class="o">=</span> <span class="n">MV</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">mv</span><span class="p">.</span><span class="n">get_answers</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that the majority voting aggregation produces hard labels (Dirac distributions).</p>

<h2 id="api-details-class-modelsmv">API details: class models.MV</h2>
<p>MV model class herits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionnary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionnary that can contain <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href=""><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">compute_baseline()</code></p>

<p>For each given task, computes the number of votes for each label.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_answers()</code></p>

<p>Returns the most voted class from the <code class="language-plaintext highlighter-rouge">baseline</code>. In case of equalities, a random choice is applied.</p>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="MV" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Generative model of Labels, Abilities, and Difficulties</title><link href="https://github.com/pages/peerannot/peerannot/models/GLAD/" rel="alternate" type="text/html" title="Generative model of Labels, Abilities, and Difficulties" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/GLAD</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/GLAD/"><![CDATA[<h2 id="model">Model</h2>

<p>GLAD’s model models both the worker ability and task difficulty into the label aggregation scheme. In order to do so, we write $$\alpha_j\in\mathbb{R}$ the worker ability and $\beta_i\in\mathbb{R}^+_\star$ the task difficulty.</p>

<p>The model is as follows: \(\mathbb{P}\bigg(y_i^{(j)}=y_i^\star\bigg)=\frac{1}{1+e^{-\alpha_j\beta_i}}.\)
We also assume that the error is uniform elsewhere, <em>i.e.</em> in a classification setting with $K$ classes that \(\mathbb{P}\bigg(y_i^{(j)}\neq y_i^\star\bigg)=\frac{1}{K-1}\bigg(1-\frac{1}{1+e^{-\alpha_j\beta_i}}\bigg).\)</p>

<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the GLAD model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> GLAD <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">GLAD</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glad</span> <span class="o">=</span> <span class="n">GLAD</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">glad</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>

<p>In the implementation, the prior on $(\alpha_j)_j$ and $(\beta_i)_i$ is set to a vector of ones.
This can be altered as follows for example with a prior on alphas of 2 and a prior on betas of 3:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glad</span> <span class="o">=</span> <span class="n">GLAD</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">glad</span><span class="p">.</span><span class="n">priorAlpha</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">glad</span><span class="p">.</span><span class="n">n_workers</span><span class="p">))</span>
<span class="n">glad</span><span class="p">.</span><span class="n">priorBeta</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">glad</span><span class="p">.</span><span class="n">n_task</span><span class="p">))</span>
<span class="n">glad</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="estimated-abilities">Estimated abilities</h3>

<p>To access the estimated confusion matrices in a variable <code class="language-plaintext highlighter-rouge">pi</code>, run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">beta</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">beta</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">alpha</span>
<span class="k">print</span><span class="p">(</span><span class="n">alpha</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">beta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (n_worker,) (n_task,)
</span></code></pre></div></div>

<h3 id="aggregate-into-hard-labels">Aggregate into hard labels</h3>

<p>After running the aggregation strategy, instead of soft labels one can recover hard labels by running:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yhat_hard</span> <span class="o">=</span> <span class="n">glad</span><span class="p">.</span><span class="n">get_answers</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that this is an <code class="language-plaintext highlighter-rouge">argmax</code> on the first dimension with a random split in case of equalities.</p>

<h2 id="api-details-class-modelsglad">API details: class models.GLAD</h2>
<p>GLAD model class that herits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionary that should contain at least <code class="language-plaintext highlighter-rouge">n_workers</code> the number of workers.
Other arguments are <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href=""><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">EM(epsilon, maxiter)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">epsilon</code>: <em>(float)</em> relative error between two iterates of the expectation of the joint likelihood</li>
  <li><code class="language-plaintext highlighter-rouge">maxiter</code>: <em>(int)</em> maximum number of iterations in the EM algorithm</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">run(epsilon, maxiter)</code></p>

<p>Run the EM algorithm for a given set of parameters</p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">epsilon</code>: <em>(float)</em> relative error between two iterates of the expectation of the joint likelihood</li>
  <li><code class="language-plaintext highlighter-rouge">maxiter</code>: <em>(int)</em> maximum number of iterations in the EM algorithm</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">save_difficulty(path)</code></p>

<p>Save coefficients $(\beta)_i$ at a given path as <code class="language-plaintext highlighter-rouge">numpy</code> arrays.</p>

<p>Parameters:</p>
<ul>
  <li>path: <em>(str)</em> file path in which coefficients are saved using the <code class="language-plaintext highlighter-rouge">np.save</code> function.</li>
</ul>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="GLAD" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Dawid and Skene</title><link href="https://github.com/pages/peerannot/peerannot/models/DS/" rel="alternate" type="text/html" title="Dawid and Skene" /><published>2023-02-19T00:00:00+00:00</published><updated>2023-02-19T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models/DS</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/DS/"><![CDATA[<h2 id="model">Model</h2>

<p>The Dawid and Skene’s model estimates one confusion matrix $\pi\in\mathbb{R}^{K\times K}$
per worker.
The model assumes that the probability for a task $x_i$ to have true label $y_i^\star=k$ follows a multinomial distribution with probabilities $\pi^{(j)}_{k,\bullet}$ for each worker.</p>

<p>The likelihood to maximize is:</p>

\[\displaystyle\prod_{i\in [n_{\texttt{task}}]}\prod_{k \in [K]}\bigg[\rho_k\prod_{j\in [n_{\texttt{worker}}]}
    \prod_{k\in [K]}\big(\pi^{(j)}_{k, k}\big)^{\unicode{x1D7D9}_{\{y_i^{(j)}=k\}}}
    \bigg]^{T_{ik}},\]

<p>with $\rho_k=\mathbb{P}(y_i^\star=k)$ and $T_{i,k}=\unicode{x1D7D9}_{\{y_i^{\star}=k \}}.$</p>
<h2 id="cli">CLI</h2>
<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> in a terminal located in the directory of answers, the DS model can be used as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>peerannnot aggregate <span class="nb">.</span> <span class="nt">--strategy</span> DS <span class="nt">--answers-file</span> answers.json
</code></pre></div></div>

<p>Note that by default, if the answers are in a file names <code class="language-plaintext highlighter-rouge">answers.json</code> the <code class="language-plaintext highlighter-rouge">--answers-file</code> argument can be omitted.</p>

<h2 id="api">API</h2>

<p>Import the aggregation model in the current session</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peerannot.models</span> <span class="kn">import</span> <span class="n">Dawid_Skene</span> <span class="k">as</span> <span class="n">DS</span>
</code></pre></div></div>

<p>Assuming the answers are in a dictionary names <code class="language-plaintext highlighter-rouge">answers</code> then run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ds</span> <span class="o">=</span> <span class="n">DS</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">ds</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">get_probas</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="estimated-abilities">Estimated abilities</h3>

<p>To access the estimated confusion matrices in a variable <code class="language-plaintext highlighter-rouge">pi</code>, run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pi</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">pi</span>
<span class="k">print</span><span class="p">(</span><span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (n_worker, n_classes, n_classes)
</span></code></pre></div></div>

<h3 id="aggregate-into-hard-labels">Aggregate into hard labels</h3>

<p>After running the aggregation strategy, instead of soft labels one can recover hard labels by running:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yhat_hard</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">get_answers</span><span class="p">()</span>
</code></pre></div></div>

<p>Note that this is an <code class="language-plaintext highlighter-rouge">argmax</code> on the first dimension with a random split in case of equalities.</p>

<h2 id="api-details-class-modelsdawid_skene">API details: class models.Dawid_Skene</h2>
<p>Dawid and Skene model class that herits from <code class="language-plaintext highlighter-rouge">CrowdModel</code></p>

<hr />
<p><code class="language-plaintext highlighter-rouge">__init__(answers, n_classes,**kwargs)</code></p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">answers</code>:<em>(dict)</em>
Dictionnary of workers answers with format
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
          </span><span class="p">{</span><span class="w">
              </span><span class="err">task</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">0</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">,</span><span class="w"> </span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">},</span><span class="w">
              </span><span class="err">task</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="err">worker</span><span class="mi">1</span><span class="err">:</span><span class="w"> </span><span class="err">label</span><span class="p">}</span><span class="w">
          </span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code>: <em>(int)</em>
Number of possible classes</li>
  <li><code class="language-plaintext highlighter-rouge">kwargs</code>: <em>(dict)</em>
Dictionnary that should contain at least $n_{\texttt{worker}}$ the number of workers.
Other arguments are <code class="language-plaintext highlighter-rouge">path_remove</code> to remove tasks identified from the <a href=""><code class="language-plaintext highlighter-rouge">WAUM</code></a> or another method.</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">get_crowd_matrix()</code></p>

<p>From the dictionnary of answers generates a tensor of size $(n_{\texttt{task}},n_{\texttt{worker}},n_{\texttt{class}})$ with $0$ where there is no collected annotation.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">init_T()</code></p>

<p>Empirical distribution initialization for the variables $T_{i,k}$</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">m_step()</code></p>

<p>Maximizing log likelihood (see eq. 2.3 and 2.4 Dawid and Skene 1979)</p>

<p>Returns (as attributes):</p>
<ul>
  <li>p: (p_j)_j probabilities that instance has true response j if drawn
      at random (class marginals)</li>
  <li>pi: number of times worker k records l when j is correct</li>
</ul>

<hr />
<p><code class="language-plaintext highlighter-rouge">e_step()</code></p>

<p>Estimate indicator variables (see eq. 2.5 Dawid and Skene 1979)</p>

<p>Returns (as attributes):</p>
<ul>
  <li>T: New estimate for indicator variables (n_task, n_worker)</li>
  <li>denom: value used to compute likelihood easily</li>
</ul>

<hr />

<p><code class="language-plaintext highlighter-rouge">log_likelihood()</code></p>

<p>Computes the logarithm of the likelihood.</p>

<hr />
<p><code class="language-plaintext highlighter-rouge">run(epsilon=1e-6, maxiter=50, verbose=False)</code></p>

<p>Run the EM algorithm</p>

<p>Parameters:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">epsilon</code>:<em>(float)</em> stopping value for the absolute difference between the log likelihood of two consecutive steps</li>
  <li><code class="language-plaintext highlighter-rouge">maxiter</code>:<em>(int)</em> Total number of steps in the EM algorithm</li>
  <li><code class="language-plaintext highlighter-rouge">verbose</code>:<em>(bool)</em> Print if the EM algorithm did not converge.</li>
</ul>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><category term="aggregation" /><category term="DS" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Models</title><link href="https://github.com/pages/peerannot/peerannot/models/" rel="alternate" type="text/html" title="Models" /><published>2023-02-19T00:00:00+00:00</published><updated>2023-02-19T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/models</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/models/"><![CDATA[<h2 id="access-models">Access models</h2>

<p>All crowdsourcing models are accessible from the <code class="language-plaintext highlighter-rouge">models</code> module.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">peerannot.models</span> <span class="k">as</span> <span class="n">pmod</span>
</code></pre></div></div>

<p>They are divided into three classes:</p>
<ul>
  <li>Aggregation strategy: from collected labels create a new label (<em>hard label</em>) or probability distribution (<em>soft label</em>) to learn from.</li>
  <li>End-to-end strategy: Directly learn from the crowdsourced labels</li>
  <li>Identification strategy:</li>
</ul>

<h2 id="aggregation-based-strategy">Aggregation based strategy<a class="anchor-link" href="#aggregation-based-strategy"><i class="fas fa-link"></i></a></h2>

<ul>
  <li><a href="/models/MV">Majority vote</a> (MV)</li>
  <li><a href="">Naive soft</a> (NS)</li>
  <li><a href="/models/DS">Dawid and Skene</a> (DS)</li>
  <li><a href="">Clustered Dawid and Skene</a> (DSWC)</li>
  <li><a href="/models/GLAD">Generative model of Labels, Abilities, and Difficulties</a> (GLAD)</li>
</ul>

<h2 id="end-to-end-strategy">End-to-end strategy<a class="anchor-link" href="#end-to-end-strategy"><i class="fas fa-link"></i></a></h2>

<ul>
  <li><a href="">CrowdLayer</a> (CL)</li>
  <li><a href="">Common Noise Adaptation Layers</a> (CoNAL)</li>
</ul>

<h2 id="identification-strategy">Identification strategy<a class="anchor-link" href="#identification-strategy"><i class="fas fa-link"></i></a></h2>

<ul>
  <li><a href="">Area Under the Margin</a> (AUM)</li>
  <li><a href="">Weighted AUM</a> (WAUM)</li>
</ul>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="models" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry><entry><title type="html">Datasets</title><link href="https://github.com/pages/peerannot/peerannot/datasets/" rel="alternate" type="text/html" title="Datasets" /><published>2023-02-19T00:00:00+00:00</published><updated>2023-02-19T00:00:00+00:00</updated><id>https://github.com/pages/peerannot/peerannot/datasets</id><content type="html" xml:base="https://github.com/pages/peerannot/peerannot/datasets/"><![CDATA[<p>With <code class="language-plaintext highlighter-rouge">peerannot</code> one of our goal is to standardize crowdsourcing datasets formats. In order to do so, we need to remind users some notations.</p>

<h2 id="notations">Notations</h2>

<p>We remind that $y_i^{(j)}\in[K]$ is the label answered by the worker $w_j$ given the task $x_i$ (<em>e.g</em> an image).
The answered label is coded as a number representing the $K$ possible classes.</p>

<h2 id="datasets-structure">Datasets structure</h2>

<p>Each dataset is defined as:</p>

<pre><code class="lang-bash">dataset
      ├── train
      │     ├── class0
      │     │     ├─ task0-&lt;vote_index_0&gt;<span class="hljs-selector-class">.png</span>
      │     │     ├─ task1-&lt;vote_index_1&gt;<span class="hljs-selector-class">.png</span>
      │     │     ├─ ...
      │     │     └─ taskn0-&lt;vote_index_n0&gt;<span class="hljs-selector-class">.png</span>
      │     ├── class1
      │     ├── ...
      │     └── classK
      ├── val
      ├── test
      ├── dataset<span class="hljs-selector-class">.py</span>
      ├── metadata<span class="hljs-selector-class">.json</span>
      └── answers.json
  </code></pre>

<p>The crowdsourced labels for each training task are contained in the <code>anwers.json</code> file. They are formatted
    as follows:</p>

<pre><code class="lang-json">{
      0: {<span class="hljs-tag">&lt;<span class="hljs-name">worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>, <span class="hljs-tag">&lt;<span class="hljs-name">another_worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>},
      1: {<span class="hljs-tag">&lt;<span class="hljs-name">yet_another_worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>,}
  }
  </code></pre>

<p>Note that the task index in the <code>answers.json</code> file might not match the order of tasks in the
    <code>train</code> folder... Thence, each task&#39;s name contains the associated votes file index.
    The number of tasks in the <code>train</code> folder <strong>must</strong> match the number of entry keys in the
    <code>answers.json</code> file.</p>
<p>The <code>metadata.json</code> file contains general information about the dataset. A minimal example would be:</p>

<pre><code class="lang-json">{
      <span class="hljs-attr">"name"</span>: &lt;dataset&gt;,
      <span class="hljs-attr">"n_classes"</span>: K,
      <span class="hljs-attr">"n_workers"</span>: &lt;n_workers&gt;,
  }
  </code></pre>

<p>In a dataset without tasks (for example when we only receive the crowdsourced labels), the <code class="language-plaintext highlighter-rouge">train</code>, <code class="language-plaintext highlighter-rouge">val</code> and <code class="language-plaintext highlighter-rouge">test</code> folders are omitted.
However, by doing so many learning strategies are not available.</p>

<h2 id="download-and-install-real-datasets-easily">Download and install real datasets easily</h2>

<p>The <code>dataset.py</code> is not mandatory but is here to facilitate the dataset&#39;s installation procedure. A
    minimal example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">mydataset</span><span class="p">:</span>
      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">__file__</span><span class="p">).</span><span class="n">parent</span><span class="p">.</span><span class="n">resolve</span><span class="p">()</span>
          <span class="c1"># download the data needed
</span>          <span class="c1"># ...
</span>
      <span class="k">def</span> <span class="nf">setfolders</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
          <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Loading data folders at </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">DIR</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
          <span class="n">train_path</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">/</span> <span class="s">"train"</span>
          <span class="n">test_path</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">/</span> <span class="s">"test"</span>
          <span class="n">valid_path</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">/</span> <span class="s">"val"</span>

          <span class="c1"># Create train/val/test tasks with matching index
</span>          <span class="c1"># ...
</span>
          <span class="k">print</span><span class="p">(</span><span class="s">"Created:"</span><span class="p">)</span>
          <span class="k">for</span> <span class="nb">set</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
              <span class="p">(</span><span class="s">"train"</span><span class="p">,</span> <span class="s">"val"</span><span class="p">,</span> <span class="s">"test"</span><span class="p">),</span> <span class="p">[</span><span class="n">train_path</span><span class="p">,</span> <span class="n">valid_path</span><span class="p">,</span> <span class="n">test_path</span><span class="p">]</span>
          <span class="p">):</span>
              <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"- </span><span class="si">{</span><span class="nb">set</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">get_crowd_labels</span><span class="p">()</span>
          <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Train crowd labels are in </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">/</span> <span class="s">'answers.json'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">get_crowd_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
          <span class="c1"># create answers.json dictionnary in presented format
</span>          <span class="c1"># ...
</span>          <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">DIR</span> <span class="o">/</span> <span class="s">"answers.json"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">answ</span><span class="p">:</span>
              <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">dictionnary</span><span class="p">,</span> <span class="n">answ</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<p>One can also instantiate in this installation file any necessary access or restrictions needed.</p>

<h2 id="simulate-datasets">Simulate datasets</h2>

<p>The <code class="language-plaintext highlighter-rouge">simulate</code> module of <code class="language-plaintext highlighter-rouge">peerannot</code> allows creating simulated labels given a strategy.</p>

<h3 id="examples">Examples</h3>

<p>Examples of simulation strategies can be found in the following:</p>
<ul>
  <li><a href="/datasets/simulate_confusions">Pairwise confusion with confusion matrices</a></li>
  <li><a href="/datasets/simulate_discrete_difficulty">Discrete levels of difficulty</a></li>
</ul>]]></content><author><name></name></author><category term="[&quot;doc&quot;]" /><category term="datasets" /><summary type="html"><![CDATA[Models available in peerannot]]></summary></entry></feed>